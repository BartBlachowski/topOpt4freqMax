% Algorithmic analysis of the implemented Olhoff approach relative to the original
% formulation of Olhoff and Du (2014).  This fragment is intended for \input{} into
% a journal manuscript; it contains no \documentclass or \begin{document}.
%
% References assumed available in the parent document:
%   \cite{OlhoffDu2014}  -- Olhoff & Du, CISM 2014 (978-3-7091-1643-2_11)
%   \cite{Yuksel2025} -- Yuksel & Yilmaz, Eng.\ Comput.\ 2025
%   \cite{Svanberg1987}  -- Svanberg, IJNME 1987
%   \cite{Du2007}  -- Du & Olhoff, Struct.\ Multidisc.\ Optim.\ 2007

\subsection*{Algorithmic Differences Between the Implemented and Original Olhoff Formulations}

The original formulation of Olhoff and Du~\cite{OlhoffDu2014} casts the
fundamental-eigenfrequency maximization problem as a max-min bound problem in
which a scalar variable $\beta \leq \omega_j^2$, $j = n, n{+}1, \ldots, J$, plays
simultaneously the role of objective and lower bound for the $J$ candidate
eigenfrequencies.  The computational procedure (Fig.~1 of that reference) consists
of a \emph{main outer loop} and an explicit \emph{inner loop}: at each outer
iteration the generalized eigenvalue problem is solved, sensitivity vectors are
assembled, and the inner loop then iteratively solves the bound sub-optimization
problem~(19) for the \emph{increments} $\Delta\rho_e$ using MMA~\cite{Svanberg1987}
or linear programming until those increments converge, after which the design
variables are updated as $\rho_e \mathrel{:=} \rho_e + \Delta\rho_e$.  No density
filter or projection is present in the original formulation.

The present implementation retains the bound variable (scaled as
$E_b = \lambda_1 / \lambda_\mathrm{ref}$) and MMA, but departs from the original
in three consequential respects.  First, a Heaviside projection
$H(\tilde{x},\beta,\eta)$ with a seven-level continuation schedule
$\beta \in \{1,2,4,8,16,32,64\}$ advancing every 40 outer iterations is
superimposed on the density field, and a grayness penalty
$\gamma(\beta/\beta_{\max}) \cdot N_\mathrm{el}^{-1} \sum_e 4\tilde{\rho}_e(1 -
\tilde{\rho}_e)$ is added to the MMA objective.  This introduces one forward and one
adjoint convolution pass per iteration for the density filter, together with one
additional adjoint pass through the Heaviside Jacobian for the penalty gradient.
Second, the inner convergence loop for increments is collapsed to a single MMA call
per outer iteration on the absolute design variables; the dual Newton solver solves
the separable convex approximation to optimality in one shot but without the explicit
increment-convergence check of the original inner loop.  Third---and most
consequentially for runtime---a \emph{trial eigensolve} is performed immediately
after every MMA update: the trial physical field is assembled into new $\mathbf{K}$
and $\mathbf{M}$ matrices, and $\min(J,3)$ modes are recomputed to reject MMA steps
that decrease $\omega_1$ by more than $1\,\%$.  This effectively doubles the number
of eigensolves per outer iteration relative to the original scheme.

Both the original and the present implementation employ the implicitly restarted
Arnoldi method (\textsc{arpack} via \texttt{eigs(\ldots,\,\textquotesingle SM\textquotesingle)})
with shift-and-invert to extract the $J = 3$ lowest eigenpairs.  Shift-and-invert
requires a sparse Cholesky factorization of $\mathbf{K}$ at each \texttt{eigs}
invocation; because $\mathbf{K}$ changes at every iteration, this factorization is
performed \emph{twice} per outer iteration in the present code.  For the
quasi-banded beam-like meshes considered here, factorization cost scales as
$O(N_\mathrm{dof}^{\,1.5})$ and dominates the per-iteration budget.

Regarding sensitivity analysis, the original formulation handles repeated
eigenvalues through an $N\times N$ sub-eigenvalue problem~(Eq.~12 of the reference),
whose solution yields the directional derivatives of the degenerate cluster via
generalized gradient vectors $\mathbf{f}_{sk}$.  The present implementation instead
applies the standard unimodal formula
$(\lambda_j)'_{\rho_e} = \boldsymbol{\varphi}_j^{\mathrm{T}}
 (\mathbf{K}'_{\rho_e} - \lambda_j \mathbf{M}'_{\rho_e})\boldsymbol{\varphi}_j$
independently to each of the $J$ modes, omitting off-diagonal terms; each elemental
sensitivity is then propagated through the Heaviside Jacobian and the adjoint filter,
requiring $J$ further convolution passes.

These deviations collectively determine the observed performance ratios.  The Yuksel
dynamic code~\cite{Yuksel2025} employs an OC bisection update
($O(N_\mathrm{el})$ per bisection step, $\approx\!15$ steps per iteration) and
performs a single eigensolve per outer iteration, with no projection chain and no
penalty-gradient filter pass.  The MMA dual Newton solver in the Olhoff
implementation costs $O(m \cdot N_\mathrm{el})$ with $m = J + 2 = 5$ constraints,
and the trial eigensolve doubles the sparse-factorization overhead.  Taken together,
these contributions yield a per-iteration cost approximately $7$--$8\times$ higher
for the Olhoff approach, as observed in Table~1 (e.g.\ $0.38$ vs.\ $0.05$~s/iter at
$320{\times}40$).  Because the Olhoff implementation terminates in $\approx\!300$
outer iterations against $\approx\!700$ for the Yuksel dynamic code, the net total
runtime ratio is $300/700 \times 7.5 \approx 3.2$--$3.5$, consistent with the
measured factor of $3.5$ across all four mesh sizes.  Both methods exhibit an
empirical per-iteration scaling of roughly $O(N_\mathrm{el}^{\,1.3})$
($0.08 \to 0.58$~s/iter and $0.01 \to 0.08$~s/iter across the mesh range), confirming
that sparse Cholesky factorization dominates over the $O(N_\mathrm{el})$ filter and
sensitivity-assembly costs.

Memory consumption follows directly from the MMA storage requirements: the
implementation retains the two MMA history iterates $\mathbf{x}^{(k-1)}$,
$\mathbf{x}^{(k-2)}$, the asymptote vectors $\ell_i$, $u_i$, and the gradient
matrix $\mathbf{dfdx}$ of size $m \times (N_\mathrm{el}{+}1)$; moreover, the trial
eigensolve requires that $\mathbf{K}_f$ and $\mathbf{M}_f$ remain allocated
simultaneously for both the current and trial fields.  At $400{\times}50$
($N_\mathrm{el} = 20{,}000$) this explains the observed $384$~MB peak against
$123$~MB for the Yuksel approach.

\subsection*{The Proposed Approach: Algorithm, Efficiency, and Practical Merits}

The proposed method replaces the dynamic eigenvalue optimization loop with a single
initial eigensolve followed by an entirely static iteration.  At initialization, the
generalized eigenvalue problem $\mathbf{K}_0\boldsymbol{\varphi}_1 =
\omega_1^2\mathbf{M}_0\boldsymbol{\varphi}_1$ is solved once on the uniform density
field $\rho_e^{(0)} = \alpha$ to obtain the fundamental eigenpair
$(\omega_1,\boldsymbol{\varphi}_1)$.  The mode shape and eigenvalue are then held
\emph{fixed} for the duration of the optimization.  At each subsequent iteration the
density-dependent mass matrix $\mathbf{M}(\mathbf{x})$ is assembled under SIMP
interpolation, and the equivalent static inertial load $\mathbf{f} =
\omega_1^2\,\mathbf{M}(\mathbf{x})\boldsymbol{\varphi}_1$ is evaluated.  The
optimization sub-problem reduces to standard compliance minimization,
$\min\,\mathbf{u}^\mathrm{T}\mathbf{K}\mathbf{u}$ subject to
$\mathbf{K}\mathbf{u}=\mathbf{f}$ and the volume constraint, updated by the OC
bisection rule.  The load sensitivity term $\partial\mathbf{f}/\partial x_e$ is
omitted, leaving a purely stiffness-based sensitivity
$\partial c/\partial x_e = -p\,x_e^{p-1}(E_0 - E_\mathrm{min})\,\mathbf{u}_e^\mathrm{T}\mathbf{K}_0\mathbf{u}_e$
that is inexpensive to compute and straightforward to filter.  A single eigensolve
is performed at termination to verify the achieved fundamental frequency.

From a computational standpoint, each iteration requires one sparse
 factorization of $\mathbf{K}_f$ (to solve the linear system
$\mathbf{K}_f\mathbf{u}_f = \mathbf{f}_f$), one mass-matrix assembly,
one sensitivity evaluation, and one OC bisection sweep — identical in
structure and cost to a standard compliance minimization step.  Because
the Krylov iterations of \textsc{arpack} are absent, the per-iteration
wall time matches that of the Yuksel  code
(e.g.\ $0.05$~s/iter at $320{\times}40$) while the number of outer
iterations is markedly lower: the fixed-mode gradient provides a stable
and consistent descent direction from the first iteration, allowing
convergence in $259$--$500$ iterations against $622$--$700$ for the
Yuksel  code across the four meshes.  The net effect is a total
runtime that is consistently the lowest of the three methods: at
$320{\times}40$ the proposed approach completes in $13.2$~s against
$33.1$~s for the Yuksel  code and $114.4$~s for the Olhoff
implementation, representing speedups of $2.5\times$ and $8.7\times$
respectively.  At $400{\times}50$ the advantage over the Yuksel code
narrows to $1.2\times$ because the Yuksel iteration count is capped and
the per-iteration costs converge, yet the proposed method remains the
fastest throughout.

Memory consumption of the proposed approach is minimal and practically
mesh-independent at small scales ($\approx\!4$~MB at $160{\times}20$ and
$240{\times}30$), growing to $21$~MB and $112$~MB at the two largest meshes
— comparable to the Yuksel  code and three to four times lower than
the Olhoff implementation.  The absence of MMA history arrays
($\mathbf{x}^{(k-1)}$, $\mathbf{x}^{(k-2)}$, asymptote vectors, and the
$(J{+}2)\times(N_\mathrm{el}{+}1)$ gradient matrix) accounts for most of
the difference relative to the Olhoff approach.

Despite the algorithmic simplification, the fundamental frequencies
achieved by the proposed method are in close agreement with those produced
by the Yuksel  code, as confirmed by the final eigensolve performed
after convergence.  This is consistent with Rayleigh's principle: because
the initial uniform design is a reasonable starting estimate of the optimal
mode shape (both are unimodal for the beam problems considered), fixing
$\boldsymbol{\varphi}_1$ empirically observed to produce only minor deviations in the
eigenvalue approximation throughout the iteration.  In engineering practice
this trade-off — a marginal reduction in the attained frequency in exchange
for a substantially shorter computation — is frequently acceptable,
particularly in preliminary design stages or when rapid exploration of
multiple boundary-condition configurations is required.

Beyond numerical performance, the simplicity of the proposed method
constitutes a practical advantage in its own right.  The algorithm requires
no continuation schedule, no bound variable, no multiple-eigenvalue
sub-problem, and no MMA solver; it reduces to a verbatim extension of a
standard compliance minimization code.  Implementation effort is minimal, the
parameter space is small (penalization exponent, filter radius, move limit,
and convergence tolerance), and the code path is deterministic and easily
debuggable.  These properties lower the barrier to adoption in custom
in-house finite-element environments where integrating a full MMA solver or
managing Heaviside continuation would represent a significant development
overhead.

\subsection{Simply Supported Beam}

The benchmark problem follows the simply supported beam configuration studied by
Du and Olhoff~\cite{Du2007} and reproduced in Yuksel and
Yilmaz~\cite{Yuksel2025}.  The admissible design domain is a rectangular
beam of length $L = 8$~m and height $H = 1$~m, discretized into $400 \times 50$
four-node quadrilateral plane-stress finite elements, yielding $N_\mathrm{el} =
20{,}000$ design variables and $N_\mathrm{dof} = 40{,}902$ degrees of freedom.
The material is isotropic with Young's modulus $E_0 = 10^7$~Pa, Poisson's ratio
$\nu = 0.3$, and mass density $\rho_0 = 1~\mathrm{kg/m}^3$.  A void
pseudo-material with $E_\mathrm{min} = 10^{-9}E_0$ and $\rho_\mathrm{min} =
10^{-9}\rho_0$ is used to prevent singularity of the global stiffness and mass
matrices.  The SIMP penalization exponent is $p = 3$ for both stiffness and
mass.  Boundary conditions follow Fig.~2(a) of Olhoff and
Du~\cite{Du2007}: both end edges are simply supported by pin constraints
applied at the mid-height node of each edge (neutral axis), leaving all other
edge nodes free.  No concentrated nonstructural mass is attached.  The
prescribed volume fraction is $\alpha = 0.5$, and a sensitivity filter with
radius $r_\mathrm{min} = 2$ elements is applied in all three implementations to
suppress checkerboard patterns and ensure mesh-independent topologies.
Convergence of the Yuksel dynamic code and the proposed approach is declared
when the maximum element-wise density change satisfies $\max|\Delta x_e| <
10^{-3}$; the Olhoff implementation uses an additional grayness criterion
($\bar{g} < 0.05$) in conjunction with the projection continuation schedule.

The optimized topologies obtained by the three approaches at the $400{\times}50$
resolution are shown in Figs.~5--7.  All three designs share the same global
load-path architecture: two stiff flanges connected by a system of diagonal
bracing members, consistent with classical beam-frequency optimization results
reported in the literature~\cite{Du2007,Yuksel2025}.  The Olhoff
approach achieves the highest fundamental frequency $\omega_1 = 174.2$~rad/s
and produces a topology in which the first two eigenfrequencies are bimodal at
the optimum---a known characteristic of the bound formulation for simply
supported beams~\cite{Du2007}.  The Yuksel dynamic code and the proposed
approach yield $\omega_1 = 160.5$~rad/s and $\omega_1 = 159.6$~rad/s
respectively, a mutual difference of less than $0.6\,\%$, while the gap with
respect to the Olhoff result is approximately $8.4\,\%$.  This discrepancy
reflects the intrinsic approximation shared by both static-load-based methods:
fixing $\omega_1$ and $\boldsymbol{\varphi}_1$ from an intermediate or initial
design introduces a bias that prevents these methods from reaching the true
eigenvalue maximum, whereas the Olhoff bound formulation directly maximizes
the smallest eigenfrequency at every iteration.  In terms of computational
resources, the Olhoff implementation requires $172.6$~s and $384$~MB of RAM
to execute $296$ outer iterations, whereas the Yuksel dynamic code converges
in $700$ iterations over $48.3$~s with $123$~MB, and the proposed approach
terminates in $500$ iterations in $40.0$~s using $112$~MB.  The proposed
method thus achieves a runtime $4.3\times$ shorter than the Olhoff
implementation and $1.2\times$ shorter than the Yuksel dynamic code while
producing a topology and fundamental frequency that are practically
indistinguishable from the Yuksel result, confirming the practical
competitiveness of the proposed approach for engineering design scenarios in
which computational turnaround time and implementation simplicity are primary
concerns.

